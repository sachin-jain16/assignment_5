{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_fashion_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIO_KgB8DyHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmUMNP0RjGdD",
        "colab_type": "text"
      },
      "source": [
        "**Dataset**\n",
        "\n",
        "Fashion MNIST Dataset\n",
        "\n",
        "**Steps**\n",
        "1)Data Augmentation\n",
        "2)Building CNN Model\n",
        "3) Adding layer of dropout(0.2) and batch normalization\n",
        "4) Adding layer of dropout(0.3) and batch normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9opxBBGEvGf",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "6d17424e-3b59-49d2-e166-5de474c175a5"
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-615a7f23-0325-4738-9765-3323d6307e86\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-615a7f23-0325-4738-9765-3323d6307e86\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train-images-idx3-ubyte to train-images-idx3-ubyte (1)\n",
            "Saving t10k-labels-idx1-ubyte to t10k-labels-idx1-ubyte\n",
            "Saving t10k-images-idx3-ubyte to t10k-images-idx3-ubyte\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4QUcKvmNlGU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "09a682ed-6871-4c67-9160-9ca172ce38e0"
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVRUF6rPE9Jq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import gzip\n",
        "import matplotlib.pyplot as plt\n",
        "from mlxtend.data import loadlocal_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8Rb418CE94h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wE038uvEAGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOz0xtyVDyH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "99d53630-5477-43d7-9ca3-5c853566b9a8"
      },
      "source": [
        "print(\"X_train-shape:\",X_train.shape)\n",
        "print(\"X_test-shape:\",X_test.shape)\n",
        "print(\"Y_train-shape:\",Y_train.shape)\n",
        "print(\"Y_test-shape:\",Y_test.shape)\n",
        "m_train = X_train.shape[0]\n",
        "m_test = X_test.shape[0]\n",
        "print (\"Number of training examples: m_train = \" + str(m_train))\n",
        "print (\"Number of testing examples: m_test = \" + str(m_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train-shape: (60000, 28, 28)\n",
            "X_test-shape: (10000, 28, 28)\n",
            "Y_train-shape: (60000,)\n",
            "Y_test-shape: (10000,)\n",
            "Number of training examples: m_train = 60000\n",
            "Number of testing examples: m_test = 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldxK5B69DyIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "737c0dbf-12a9-4dd9-c11e-6cddd251d964"
      },
      "source": [
        "np.random.seed(0);\n",
        "indices = list(np.random.randint(m_train,size=9))\n",
        "print(indices)\n",
        "for i in range(len(indices)):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_train[indices[i]].reshape(28,28),interpolation='none' )\n",
        "    plt.title(\"Index {} Class {}\".format(indices[i], Y_train[indices[i]]))\n",
        "    plt.tight_layout()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2732, 43567, 42613, 52416, 45891, 21243, 30403, 32103, 41993]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEYCAYAAACKvFuOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWT5yip5DyIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLvcYHjdDyIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaZd7jCcDyIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=X_train.reshape(60000,28,28).copy()\n",
        "x_test=X_test.reshape(10000,28,28).copy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BS8QEnNBDyIb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "46e3f558-2512-425b-c7ef-486a04f32b67"
      },
      "source": [
        "print(\"x_train-shape:\",x_train.shape)\n",
        "print(\"x_test-shape:\",x_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train-shape: (60000, 28, 28)\n",
            "x_test-shape: (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW5i1TtjDyIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for fliping the image\n",
        "def data_augmentation(x_train):\n",
        "    x_train_aug = x_train\n",
        "    def flip_image(x_train):\n",
        "        x_flip =[]   \n",
        "        for i in range(len(x_train)):\n",
        "            flipped_img = np.fliplr(x_train[i])\n",
        "            x_flip.append(flipped_img)\n",
        "        return x_flip  \n",
        "\n",
        "\n",
        "# function for horizontal shifting\n",
        "    def horizontal_shift(x_train):\n",
        "        x_shift=[]\n",
        "        WIDTH =28\n",
        "        HEIGHT =28\n",
        "        for k in range(len(x_train)):\n",
        "            for j in range(WIDTH):\n",
        "                for i in range(HEIGHT):\n",
        "                    if i < HEIGHT -20:\n",
        "                        x_train[k][j][i] = x_train[k][j][i+20]\n",
        "                        x_shift.append(x_train[k])\n",
        "        return x_shift\n",
        "\n",
        "\n",
        "# function for adding random noise\n",
        "    def noise_(x_train):\n",
        "        m  = len(x_train)\n",
        "        HEIGHT = 28\n",
        "        WIDTH  =28\n",
        "        noise = np.random.randint( 5,size = (m, 28, 28), dtype = 'uint8')\n",
        "        for i in range(m):\n",
        "            for j in range(WIDTH):\n",
        "                for k in range(HEIGHT):\n",
        "                    if (x_train[i][j][k] <=250):\n",
        "                        x_train[i][j][k] += noise[i][j][k]\n",
        "        return x_train\n",
        "\n",
        "\n",
        "# function for rotating image\n",
        "    def image_rotation(x_train):\n",
        "        length,rows,cols = x_train.shape\n",
        "        rotate_image=[]\n",
        "        for i in range(length):\n",
        "            M = cv2.getRotationMatrix2D((cols/2,rows/2),90,1)\n",
        "            dst = cv2.warpAffine(x_train[i],M,(cols,rows))\n",
        "            rotate_image.append(dst)\n",
        "        return rotate_image\n",
        "\n",
        "# color shifting of the image\n",
        "    def color_shift(x_train):\n",
        "        color_contrast=[]\n",
        "        length,rows,columns =  x_train.shape\n",
        "        for k in range (length):\n",
        "            for i in range(28):\n",
        "                for j in range(28):\n",
        "                    x_train[k][i][j] = x_train[k][i][j]-8\n",
        "            color_contrast.append(x_train[k])             \n",
        "                    \n",
        "        return color_contrast\n",
        "    \n",
        "    #flip_data = flip_image(x_train)\n",
        "    #x_train_aug = np.vstack((x_train_aug,flip_data))\n",
        "    #h_shift    = horizontal\n",
        "    #x_train_aug= np.vstack((x_train_aug,h_shift))\n",
        "    #noise_data = noise_(x_train)\n",
        "    #x_train_aug= np.vstack((x_train_aug,noise_data))\n",
        "    rotate_image = image_rotation(x_train)\n",
        "    x_train_aug= np.vstack((x_train_aug,rotate_image))\n",
        "    #color_contrast = color_shift(x_train)\n",
        "    #x_train_aug= np.vstack((x_train_aug,color_contrast))\n",
        "    return x_train_aug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNBxK2DcDyIm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b50193dd-5855-4d69-9a27-f6c53b04b6b2"
      },
      "source": [
        "x_train_aug = data_augmentation(x_train)\n",
        "x_train_aug.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nam4B47yDyIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def y_augmentation(y_train):\n",
        "    y_list =np.array(Y_train).tolist()\n",
        "    #print(type(y_list))\n",
        "    num_of_transformations =int(len(x_train_aug)/len(x_train))\n",
        "    y_list = y_list*num_of_transformations\n",
        "    y_train = np.array(y_list)\n",
        "    y_one_hot = np.eye(10)[y_train]\n",
        "    y_one_hot\n",
        "    return y_one_hot\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAq1dAscDyIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "15a49bbf-52fa-48d5-bfc0-564f17e8b973"
      },
      "source": [
        "y_train = y_augmentation(Y_train)\n",
        "print(len(y_train))\n",
        "y_train.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKyxliMoDyI6",
        "colab_type": "text"
      },
      "source": [
        "# Building CNN model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1hG15RDDyI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0tKQmrgDyJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f1e54b7-60df-402c-e831-0f3ccfed55cf"
      },
      "source": [
        "train_X = x_train_aug.reshape(-1, 28, 28, 1)\n",
        "train_X.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8uiLGNhDyJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_X_OqyTDyJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x = tf.placeholder(\"float\", [None, 28,28,1])\n",
        "y = tf.placeholder(\"float\", [None, n_classes])\n",
        "training_iters = 200 \n",
        "learning_rate = 0.001 \n",
        "batch_size = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xR_Wy9CDyJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return tf.nn.relu(x)\n",
        "def maxpool2d(x, k=2):\n",
        "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_93kR62DyJS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2ed81467-f5e6-4d0b-845f-9ca6947d4e6a"
      },
      "source": [
        "weights = {\n",
        "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "    'out': tf.get_variable('W6', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
        "}\n",
        "biases = {\n",
        "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc2': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bc3': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bd1': tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'out': tf.get_variable('B4', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "}\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0619 04:06:55.006191 139985517381504 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VxiG0iLDyJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_aug = tf.cast(train_X,tf.float32)\n",
        "def conv_net(x, weights, biases):  \n",
        "\n",
        "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    print(conv1.shape)\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "    print(conv1.shape)\n",
        "\n",
        "    # Convolution Layer\n",
        "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    print(conv2.shape)\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "    print(conv2.shape)\n",
        "\n",
        "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
        "    print(conv3.shape)\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
        "    conv3 = maxpool2d(conv3, k=2)\n",
        "    print(conv3.shape)\n",
        "\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    print(fc1.shape)\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    print(fc1.shape)\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    print(fc1.shape)\n",
        "    # Output, class prediction\n",
        "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9IxxEFoDyJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d582b542-f163-44b6-f214-8df84cb76914"
      },
      "source": [
        "#pred = conv_net(x_train_aug, weights, biases)\n",
        "print(x_aug)\n",
        "weights['wc1'].dtype\n",
        "biases[\"bc1\"].dtype"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Cast:0\", shape=(120000, 28, 28, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32_ref"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu3xxJyeDyJg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e27c82a-dcb4-4cf2-cd95-e9b7a1983662"
      },
      "source": [
        "print(weights['wc1'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'W0:0' shape=(3, 3, 1, 32) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV70VZE-DyJm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "538db373-4d8e-4a84-8fdb-f239857e8909"
      },
      "source": [
        "pred = conv_net(x, weights, biases)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 28, 28, 32)\n",
            "(?, 14, 14, 32)\n",
            "(?, 14, 14, 64)\n",
            "(?, 7, 7, 64)\n",
            "(?, 7, 7, 128)\n",
            "(?, 4, 4, 128)\n",
            "(?, 2048)\n",
            "(?, 128)\n",
            "(?, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5swp0gDDyJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "e2965a83-13ad-4166-c41f-f34b6ba544c2"
      },
      "source": [
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0619 04:07:31.172777 139985517381504 deprecation.py:323] From <ipython-input-24-e03b9e7a87b3>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIWP2_krDyJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
        "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
        "\n",
        "#calculate accuracy across all the given images and average them out. \n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrgiYL3kDyJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQC95PAGDyJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9321c2dd-8862-489f-a99d-6f02af444f82"
      },
      "source": [
        "m = int(len(x_train_aug)/batch_size)\n",
        "print(m)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6pvZ0-wa8Fu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "454d224a-c051-4221-d757-4c2e23531949"
      },
      "source": [
        "x_test = X_test.reshape(-1, 28, 28, 1)\n",
        "x_test.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO6pzdxucZU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8542c6d3-7c00-45a4-cb34-c9fef019aaf4"
      },
      "source": [
        "y_test = np.eye(10)[Y_test]\n",
        "y_test.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ybLc5KbDyJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3143
        },
        "outputId": "1dea7612-0a1d-4fef-c563-6555354b029a"
      },
      "source": [
        "iterations =60\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init) \n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    train_accuracy = []\n",
        "    test_accuracy = []\n",
        "    saver=tf.train.Saver()\n",
        "    initial =0\n",
        "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
        "    \n",
        "    for i in range(iterations):\n",
        "        for batch in range(m):\n",
        "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
        "            batch_y = y_train[batch*batch_size:min((batch+1)*batch_size,len(y_train))]    \n",
        "            # Run optimization op (backprop).\n",
        "                # Calculate batch loss and accuracy\n",
        "            opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
        "                                                              y: batch_y})\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
        "                                                              y: batch_y})\n",
        "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
        "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                      \"{:.5f}\".format(acc))\n",
        "        print(\"Optimization Finished!\")\n",
        "        \n",
        "        loss_val,acc_val=sess.run([cost,accuracy],feed_dict={x:x_test,y:y_test})\n",
        "        if acc_val>initial:\n",
        "            print(\"accuracy:\",acc_val)\n",
        "            saver.save(sess,'./result')\n",
        "        \n",
        "\n",
        "        # Calculate accuracy for all 10000 mnist test images\n",
        "        #test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
        "        #train_loss.append(loss)\n",
        "        #test_loss.append(valid_loss)\n",
        "        #train_accuracy.append(acc)\n",
        "        #test_accuracy.append(test_acc)\n",
        "        #print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
        "    summary_writer.close()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter 0, Loss= 0.243933, Training Accuracy= 0.91500\n",
            "Optimization Finished!\n",
            "accuracy: 0.0769\n",
            "Iter 1, Loss= 0.226321, Training Accuracy= 0.91000\n",
            "Optimization Finished!\n",
            "accuracy: 0.1872\n",
            "Iter 2, Loss= 0.199301, Training Accuracy= 0.92000\n",
            "Optimization Finished!\n",
            "accuracy: 0.4707\n",
            "Iter 3, Loss= 0.181005, Training Accuracy= 0.93500\n",
            "Optimization Finished!\n",
            "accuracy: 0.6142\n",
            "Iter 4, Loss= 0.164195, Training Accuracy= 0.94000\n",
            "Optimization Finished!\n",
            "accuracy: 0.7302\n",
            "Iter 5, Loss= 0.141694, Training Accuracy= 0.95000\n",
            "Optimization Finished!\n",
            "accuracy: 0.7647\n",
            "Iter 6, Loss= 0.152926, Training Accuracy= 0.95500\n",
            "Optimization Finished!\n",
            "accuracy: 0.7574\n",
            "Iter 7, Loss= 0.148277, Training Accuracy= 0.95000\n",
            "Optimization Finished!\n",
            "accuracy: 0.793\n",
            "Iter 8, Loss= 0.115755, Training Accuracy= 0.95500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8157\n",
            "Iter 9, Loss= 0.089433, Training Accuracy= 0.97000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8053\n",
            "Iter 10, Loss= 0.101929, Training Accuracy= 0.95500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8239\n",
            "Iter 11, Loss= 0.069429, Training Accuracy= 0.97000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8398\n",
            "Iter 12, Loss= 0.060024, Training Accuracy= 0.97500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8346\n",
            "Iter 13, Loss= 0.056944, Training Accuracy= 0.98500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8265\n",
            "Iter 14, Loss= 0.047731, Training Accuracy= 0.99000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8354\n",
            "Iter 15, Loss= 0.036513, Training Accuracy= 0.99000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8345\n",
            "Iter 16, Loss= 0.043032, Training Accuracy= 0.98500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8424\n",
            "Iter 17, Loss= 0.077587, Training Accuracy= 0.98000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8091\n",
            "Iter 18, Loss= 0.065021, Training Accuracy= 0.97000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8359\n",
            "Iter 19, Loss= 0.052576, Training Accuracy= 0.98000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8335\n",
            "Iter 20, Loss= 0.037946, Training Accuracy= 0.99000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8519\n",
            "Iter 21, Loss= 0.030404, Training Accuracy= 0.98500\n",
            "Optimization Finished!\n",
            "accuracy: 0.854\n",
            "Iter 22, Loss= 0.025290, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.852\n",
            "Iter 23, Loss= 0.019937, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.862\n",
            "Iter 24, Loss= 0.016217, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8681\n",
            "Iter 25, Loss= 0.014341, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8689\n",
            "Iter 26, Loss= 0.025903, Training Accuracy= 0.99000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8435\n",
            "Iter 27, Loss= 0.015549, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8572\n",
            "Iter 28, Loss= 0.014616, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8608\n",
            "Iter 29, Loss= 0.045130, Training Accuracy= 0.98000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8596\n",
            "Iter 30, Loss= 0.024535, Training Accuracy= 0.99000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8639\n",
            "Iter 31, Loss= 0.011974, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8782\n",
            "Iter 32, Loss= 0.009575, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8737\n",
            "Iter 33, Loss= 0.007429, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8745\n",
            "Iter 34, Loss= 0.022473, Training Accuracy= 0.99000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8615\n",
            "Iter 35, Loss= 0.005209, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8628\n",
            "Iter 36, Loss= 0.008566, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8709\n",
            "Iter 37, Loss= 0.009489, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.879\n",
            "Iter 38, Loss= 0.005834, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8647\n",
            "Iter 39, Loss= 0.019980, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8672\n",
            "Iter 40, Loss= 0.004153, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8683\n",
            "Iter 41, Loss= 0.045606, Training Accuracy= 0.98500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8575\n",
            "Iter 42, Loss= 0.023093, Training Accuracy= 0.99000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8627\n",
            "Iter 43, Loss= 0.009507, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8734\n",
            "Iter 44, Loss= 0.007068, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8775\n",
            "Iter 45, Loss= 0.008182, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8672\n",
            "Iter 46, Loss= 0.011763, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8724\n",
            "Iter 47, Loss= 0.002966, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8721\n",
            "Iter 48, Loss= 0.004153, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8727\n",
            "Iter 49, Loss= 0.015643, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8614\n",
            "Iter 50, Loss= 0.004384, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8735\n",
            "Iter 51, Loss= 0.004726, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8759\n",
            "Iter 52, Loss= 0.021428, Training Accuracy= 0.99000\n",
            "Optimization Finished!\n",
            "accuracy: 0.873\n",
            "Iter 53, Loss= 0.005786, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8701\n",
            "Iter 54, Loss= 0.010914, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8783\n",
            "Iter 55, Loss= 0.003736, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8821\n",
            "Iter 56, Loss= 0.010293, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8772\n",
            "Iter 57, Loss= 0.017554, Training Accuracy= 0.99500\n",
            "Optimization Finished!\n",
            "accuracy: 0.8799\n",
            "Iter 58, Loss= 0.001787, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8776\n",
            "Iter 59, Loss= 0.006212, Training Accuracy= 1.00000\n",
            "Optimization Finished!\n",
            "accuracy: 0.8791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRDkrW1YDyJ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af1697fa-e272-4ea4-bd62-d0d038a1db93"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "imported_graph=tf.train.import_meta_graph('result.meta')\n",
        "with tf.Session() as sess:\n",
        "  imported_graph.restore(sess,'./result')\n",
        "  we=sess.run('W0/Initializer/random_uniform/shape:0')\n",
        "  print(we)\n",
        "  #loss_val,acc_val=sess.run([cost,accuracy],feed_dict={'Placeholder:0':x_test,'Placeholder_1:0':y_test})"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3  3  1 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwmPESn0DyKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_net_modified(x, weights, biases,dropout):  \n",
        "\n",
        "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
        "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    print(conv1.shape)\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
        "    conv1 = maxpool2d(conv1, k=2)\n",
        "    print(conv1.shape)\n",
        "    #adding dropout layer\n",
        "    conv1 = tf.layers.dropout(conv1,dropout)\n",
        "    # batch normalization\n",
        "    conv1 = tf.layers.batch_normalization(conv1)\n",
        "\n",
        "    # Convolution Layer\n",
        "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
        "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    print(conv2.shape)\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
        "    conv2 = maxpool2d(conv2, k=2)\n",
        "    print(conv2.shape)\n",
        "    #adding dropout layer\n",
        "    conv2 = tf.layers.dropout(conv2,dropout)\n",
        "    # batch normalization\n",
        "    conv2 = tf.layers.batch_normalization(conv2)\n",
        "    \n",
        "\n",
        "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
        "    print(conv3.shape)\n",
        "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
        "    conv3 = maxpool2d(conv3, k=2)\n",
        "    print(conv3.shape)\n",
        "    #adding dropout layer\n",
        "    conv3 = tf.layers.dropout(conv3,dropout)\n",
        "    # batch normalization\n",
        "    conv3 = tf.layers.batch_normalization(conv3)\n",
        "\n",
        "\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    print(fc1.shape)\n",
        "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "    print(fc1.shape)\n",
        "    fc1 = tf.nn.relu(fc1)\n",
        "    print(fc1.shape)\n",
        "    # Output, class prediction\n",
        "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
        "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYiUYUZp52ic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "41ecf1e2-6a9c-4b58-e743-da8f102dee01"
      },
      "source": [
        "pred_m = conv_net_modified(x, weights, biases,0.2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 28, 28, 32)\n",
            "(?, 14, 14, 32)\n",
            "(?, 14, 14, 64)\n",
            "(?, 7, 7, 64)\n",
            "(?, 7, 7, 128)\n",
            "(?, 4, 4, 128)\n",
            "(?, 2048)\n",
            "(?, 128)\n",
            "(?, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP15srjD6AZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_m = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred_m, labels=y))\n",
        "\n",
        "optimizer_m = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost_m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saXEuKXCCOQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
        "correct_prediction = tf.equal(tf.argmax(pred_m, 1), tf.argmax(y, 1))\n",
        "\n",
        "#calculate accuracy across all the given images and average them out. \n",
        "accuracy_m = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFxxARYQArZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "a6a3852d-5723-4f47-f6af-ccf063161e4b"
      },
      "source": [
        "iterations = 10\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    train_loss_modified = []\n",
        "    train_accuracy_modified = []\n",
        "    test_loss_modified = []\n",
        "    test_accuracy_modified = []\n",
        "    saver_modified = tf.train.Saver()\n",
        "    accu_modified = 0\n",
        "    \n",
        "    for i in range(iterations):\n",
        "        for batch in range(m):\n",
        "            x_batch = train_X[batch*batch_size:min((batch+1)*batch_size, len(train_X))]\n",
        "            y_batch = y_train[batch*batch_size:min((batch+1)*batch_size, len(y_train))]\n",
        "            \n",
        "            opt_modified = sess.run(optimizer_m, feed_dict={x:x_batch, y:y_batch})\n",
        "            \n",
        "            loss_m, acc_m = sess.run([cost_m, accuracy_m], feed_dict={x:x_batch, y:y_batch})\n",
        "        \n",
        "        print(\"epoch \" + str(i+1) + \", Loss= \" + \"{:.6f}\".format(loss_m) + \", Training Accuracy = \" + \\\n",
        "             \"{:.5f}\".format(acc_m))\n",
        "        print(\"Optimization Finished!\")\n",
        "        \n",
        "        test_acc_m, valid_loss_m = sess.run([accuracy_m, cost_m], feed_dict={x:x_test, y:y_test})\n",
        "        \n",
        "        train_loss_modified.append(loss_m)\n",
        "        test_loss_modified.append(valid_loss_m)\n",
        "        train_accuracy_modified.append(acc_m)\n",
        "        test_accuracy_modified.append(test_acc_m)\n",
        "        \n",
        "        print(\"Testing Accuracy:\", \"{:.5f}\".format(test_acc_m))\n",
        "        \n",
        "        if(test_acc_m > accu_modified):\n",
        "            accu_modified = test_acc_m\n",
        "            saver_modified.save(sess,'result_modified')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, Loss= 0.266753, Training Accuracy = 0.90500\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.05050\n",
            "epoch 2, Loss= 0.249915, Training Accuracy = 0.90500\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.14920\n",
            "epoch 3, Loss= 0.255670, Training Accuracy = 0.89000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.46020\n",
            "epoch 4, Loss= 0.187497, Training Accuracy = 0.93500\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.67660\n",
            "epoch 5, Loss= 0.160745, Training Accuracy = 0.95500\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.74450\n",
            "epoch 6, Loss= 0.120001, Training Accuracy = 0.95500\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.79230\n",
            "epoch 7, Loss= 0.114654, Training Accuracy = 0.96000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.81010\n",
            "epoch 8, Loss= 0.102511, Training Accuracy = 0.97000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.82430\n",
            "epoch 9, Loss= 0.095972, Training Accuracy = 0.96500\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.82800\n",
            "epoch 10, Loss= 0.073788, Training Accuracy = 0.98000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.81160\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxRDvlW9PXH0",
        "colab_type": "text"
      },
      "source": [
        "**Drpout =0.3, Batch Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2otcynGqDT5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "24573991-b9b0-48d9-8ecb-df04a5c830d9"
      },
      "source": [
        "pred_m_1 = conv_net_modified(x, weights, biases,0.3)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 28, 28, 32)\n",
            "(?, 14, 14, 32)\n",
            "(?, 14, 14, 64)\n",
            "(?, 7, 7, 64)\n",
            "(?, 7, 7, 128)\n",
            "(?, 4, 4, 128)\n",
            "(?, 2048)\n",
            "(?, 128)\n",
            "(?, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNf4LwtZPxIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_m_1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred_m_1, labels=y))\n",
        "\n",
        "optimizer_m_1 = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost_m_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sb8u17xP86A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
        "correct_prediction_m_1 = tf.equal(tf.argmax(pred_m, 1), tf.argmax(y, 1))\n",
        "\n",
        "#calculate accuracy across all the given images and average them out. \n",
        "accuracy_m_1 = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR8wX75jPUOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "17337b9f-1193-4b7a-e6a7-9745b3114cad"
      },
      "source": [
        "iterations = 10\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    train_loss_modified = []\n",
        "    train_accuracy_modified = []\n",
        "    test_loss_modified = []\n",
        "    test_accuracy_modified = []\n",
        "    saver_modified = tf.train.Saver()\n",
        "    accu_modified = 0\n",
        "    \n",
        "    for i in range(iterations):\n",
        "        for batch in range(m):\n",
        "            x_batch = train_X[batch*batch_size:min((batch+1)*batch_size, len(train_X))]\n",
        "            y_batch = y_train[batch*batch_size:min((batch+1)*batch_size, len(y_train))]\n",
        "            \n",
        "            opt_modified = sess.run(optimizer_m_1, feed_dict={x:x_batch, y:y_batch})\n",
        "            \n",
        "            loss_m, acc_m = sess.run([cost_m_1, accuracy_m_1], feed_dict={x:x_batch, y:y_batch})\n",
        "        \n",
        "        print(\"epoch \" + str(i+1) + \", Loss= \" + \"{:.6f}\".format(loss_m) + \", Training Accuracy = \" + \\\n",
        "             \"{:.5f}\".format(acc_m))\n",
        "        print(\"Optimization Finished!\")\n",
        "        \n",
        "        test_acc_m, valid_loss_m = sess.run([accuracy_m_1, cost_m_1], feed_dict={x:x_test, y:y_test})\n",
        "        \n",
        "        train_loss_modified.append(loss_m)\n",
        "        test_loss_modified.append(valid_loss_m)\n",
        "        train_accuracy_modified.append(acc_m)\n",
        "        test_accuracy_modified.append(test_acc_m)\n",
        "        \n",
        "        print(\"Testing Accuracy:\", \"{:.5f}\".format(test_acc_m))\n",
        "        \n",
        "        if(test_acc_m > accu_modified):\n",
        "            accu_modified = test_acc_m\n",
        "            saver_modified.save(sess,'result_modified_1')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, Loss= 0.266009, Training Accuracy = 0.90000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.09040\n",
            "epoch 2, Loss= 0.224487, Training Accuracy = 0.91500\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.18600\n",
            "epoch 3, Loss= 0.182012, Training Accuracy = 0.94000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.31500\n",
            "epoch 4, Loss= 0.198215, Training Accuracy = 0.93000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.61630\n",
            "epoch 5, Loss= 0.176522, Training Accuracy = 0.93500\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.69860\n",
            "epoch 6, Loss= 0.150037, Training Accuracy = 0.95000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.72260\n",
            "epoch 7, Loss= 0.122166, Training Accuracy = 0.96000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.74810\n",
            "epoch 8, Loss= 0.093452, Training Accuracy = 0.96000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.76650\n",
            "epoch 9, Loss= 0.095329, Training Accuracy = 0.95000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.74660\n",
            "epoch 10, Loss= 0.084302, Training Accuracy = 0.95000\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.72800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w5qZOsPQjjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}